{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm_notebook\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "## It's better to ensure the current path\n",
    "os.chdir('/home/jupyter/competition/learning-to-drive/doc')\n",
    "sys.path.append('/home/jupyter/competition/learning-to-drive/lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SFP91yyychql"
   },
   "source": [
    "# Getting Started:\n",
    "## A simple driving model training and evaluation pipeline using the Drive360 dataset and PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eeTTXKFEchqm"
   },
   "source": [
    "## Loading data from Drive360 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9dUjc8BHchqn"
   },
   "source": [
    "The **dataset.py** file contains the 3 classes necessary for creating a Drive360Loader. Using the **config.json** file to specify the location of the csv and data directory, we can generate phase (train, validation, test) specific data loaders that can output samples from each set. Adjust the **dataset.py** to your preferred training framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5075,
     "status": "ok",
     "timestamp": 1569969319418,
     "user": {
      "displayName": "Xiaoxi Zhao",
      "photoUrl": "",
      "userId": "07703831001558590239"
     },
     "user_tz": 240
    },
    "id": "FMS1e2vVchqo",
    "outputId": "3c6f4b5c-097e-4de6-cc7e-84a152d06319"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: train # of data: 78292\n",
      "Phase: validation # of data: 5151\n",
      "Phase: test # of data: 14010\n",
      "Loaded train loader with the following data available as a dict.\n",
      "Index(['cameraRight', 'cameraFront', 'cameraRear', 'cameraLeft', 'canSteering',\n",
      "       'canSpeed', 'chapter'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from dataset import Drive360Loader\n",
    "\n",
    "# load the config.json file that specifies data \n",
    "# location parameters and other hyperparameters \n",
    "# required.\n",
    "config = json.load(open('./config.json'))\n",
    "\n",
    "normalize_targets = config['target']['normalize']\n",
    "target_mean = config['target']['mean']\n",
    "target_std = config['target']['std']\n",
    "\n",
    "# create a train, validation and test data loader\n",
    "train_loader = Drive360Loader(config, 'train')\n",
    "validation_loader = Drive360Loader(config, 'validation')\n",
    "test_loader = Drive360Loader(config, 'test')\n",
    "\n",
    "# print the data (keys) available for use. See full \n",
    "# description of each data type in the documents.\n",
    "print('Loaded train loader with the following data available as a dict.')\n",
    "print(train_loader.drive360.dataframe.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/competition/learning-to-drive/doc'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KMV2svdJchqt"
   },
   "source": [
    "## Training a basic driving model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bvQMkdW0chqu"
   },
   "source": [
    "Create your driving model. This is specific to your learning framework. \n",
    "\n",
    "Below we give a very basic dummy model that uses the front facing camera and a resnet34 + LSTM architecture to predict canSteering and canSpeed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Non_local_pytorch.lib.non_local_embedded_gaussian import NONLocalBlock2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8439,
     "status": "ok",
     "timestamp": 1569969364254,
     "user": {
      "displayName": "Xiaoxi Zhao",
      "photoUrl": "",
      "userId": "07703831001558590239"
     },
     "user_tz": 240
    },
    "id": "QQNxTxMOchqv",
    "outputId": "26246366-3f5a-4930-bf2f-64433676363c"
   },
   "outputs": [],
   "source": [
    "class NonLocalModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NonLocalModel, self).__init__()\n",
    "        final_concat_size = 0\n",
    "        \n",
    "        # Main CNN\n",
    "        cnn = models.resnet34(pretrained=True)\n",
    "        for i, layer in enumerate(cnn.children()):\n",
    "            if i <= 6:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = False\n",
    "        self.features = nn.Sequential(\n",
    "            *list(cnn.children())[0:4],\n",
    "            NONLocalBlock2D(64),\n",
    "            list(cnn.children())[4],\n",
    "            NONLocalBlock2D(64),\n",
    "            list(cnn.children())[5],\n",
    "            NONLocalBlock2D(128),\n",
    "            list(cnn.children())[6],\n",
    "            NONLocalBlock2D(256),\n",
    "            *list(cnn.children())[7:9]\n",
    "        )\n",
    "        # self.resnet_output = nn.Sequential(*list(cnn.children())[:-2])\n",
    "        self.intermediate = nn.Sequential(nn.Linear(\n",
    "                          cnn.fc.in_features, 128),\n",
    "                          nn.ReLU())\n",
    "        final_concat_size += 128\n",
    "\n",
    "        # Main LSTM\n",
    "        self.gru = nn.GRU(input_size=128,\n",
    "                            hidden_size=64,\n",
    "                            num_layers=3,\n",
    "                            batch_first=False)\n",
    "        final_concat_size += 64\n",
    "        \n",
    "        # Angle Regressor\n",
    "        self.control_angle = nn.Sequential(\n",
    "            nn.Linear(final_concat_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        # Speed Regressor\n",
    "        self.control_speed = nn.Sequential(\n",
    "            nn.Linear(final_concat_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, data):\n",
    "        module_outputs = []\n",
    "        gru_i = []\n",
    "        # Loop through temporal sequence of\n",
    "        # front facing camera images and pass \n",
    "        # through the cnn.\n",
    "        for k, v in data['cameraFront'].items():\n",
    "            if torch.cuda.is_available():\n",
    "                v = v.cuda()\n",
    "            x = self.features(v)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.intermediate(x)\n",
    "            gru_i.append(x)\n",
    "            # feed the current front facing camera\n",
    "            # output directly into the \n",
    "            # regression networks.\n",
    "            if k == 0:\n",
    "                module_outputs.append(x)\n",
    "\n",
    "        # Feed temporal outputs of CNN into LSTM\n",
    "        self.gru.flatten_parameters()\n",
    "        i_gru, _ = self.gru(torch.stack(gru_i))\n",
    "        module_outputs.append(i_gru[-1])\n",
    "        \n",
    "        # Concatenate current image CNN output \n",
    "        # and LSTM output.\n",
    "        x_cat = torch.cat(module_outputs, dim=-1)\n",
    "        \n",
    "        # Feed concatenated outputs into the \n",
    "        # regession networks.\n",
    "        prediction = {'canSteering': torch.squeeze(self.control_angle(x_cat)),\n",
    "                      'canSpeed': torch.squeeze(self.control_speed(x_cat))}\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5EEBPLHnchqy"
   },
   "source": [
    "### Training and validation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2662274,
     "status": "ok",
     "timestamp": 1569977854128,
     "user": {
      "displayName": "Xiaoxi Zhao",
      "photoUrl": "",
      "userId": "07703831001558590239"
     },
     "user_tz": 240
    },
    "id": "3WvoNo2Ychqz",
    "outputId": "d0093f0a-0ebb-4c58-fd5d-8d0ad3c93a7c"
   },
   "outputs": [],
   "source": [
    "def train_nn(train_loader, validation_loader, model, optimizer, \n",
    "             criterion, epochs=5, validation=True, load_path='', save_path='', print_freq = 200):\n",
    "    '''Training the model\n",
    "    Args:\n",
    "        validation: boolean, whether process validation\n",
    "        load_path: string, the model weights file to load\n",
    "        save_path: string, the model weights file to save\n",
    "    Returns:\n",
    "    '''\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        # model = nn.DataParallel(model)\n",
    "    if os.path.exists(load_path):\n",
    "        print('='*10 + 'loading weights from ' + load_path + '='*10)\n",
    "        checkpoint = torch.load(load_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        print('='*10 + 'loading finished' + '='*10)\n",
    "    else:\n",
    "        print('load_path does not exist!')\n",
    "        \n",
    "    train_metrics = {\n",
    "        'angle_loss': {},\n",
    "        'speed_loss': {}\n",
    "    }\n",
    "    validation_metrics = {\n",
    "        'angle_loss': {},\n",
    "        'speed_loss': {}\n",
    "    }\n",
    "    for epoch in range(epochs):\n",
    "        print('='*10 + 'start ' + str(epoch+1) + ' epoch' + '='*10)\n",
    "        model.train()\n",
    "        angle_loss = 0.0\n",
    "        speed_loss = 0.0\n",
    "        since = datetime.now()\n",
    "        cnt = 0\n",
    "        for batch_idx, (data, target) in enumerate(tqdm_notebook(train_loader)):\n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(data)\n",
    "            loss1 = criterion(prediction['canSteering'], target['canSteering'].cuda())\n",
    "            loss2 = criterion(prediction['canSpeed'], target['canSpeed'].cuda())\n",
    "            loss = loss1 + loss2\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # print statistics\n",
    "            angle_loss += loss1.item()\n",
    "            speed_loss += loss2.item()\n",
    "            cnt += 1\n",
    "#             if batch_idx > 5:\n",
    "#                 break\n",
    "            if (batch_idx+1) % print_freq == 0:\n",
    "                if normalize_targets:\n",
    "                    angle_loss = (angle_loss * target_std['canSteering']**2) / cnt\n",
    "                    speed_loss = (speed_loss * target_std['canSpeed']**2) / cnt\n",
    "                else:\n",
    "                    angle_loss /= cnt\n",
    "                    speed_loss /= cnt\n",
    "                train_metrics['angle_loss'].setdefault(str(epoch), []).append(angle_loss)\n",
    "                train_metrics['speed_loss'].setdefault(str(epoch), []).append(speed_loss)\n",
    "                print('[epoch: %d, batch: %5d] time: %.2f angle_loss: %.2f speed_loss: %.2f' %\n",
    "                      (epoch + 1, batch_idx + 1, (datetime.now() - since).total_seconds(), angle_loss, speed_loss))\n",
    "                angle_loss = 0.0\n",
    "                speed_loss = 0.0\n",
    "                since = datetime.now()\n",
    "                cnt = 0\n",
    "        print('='*10 + 'saving the model to' + save_path + '='*10)\n",
    "        torch.save({\n",
    "            \"model_state_dict\":model.state_dict(),\n",
    "            \"angle_loss\": angle_loss,\n",
    "            \"speed_loss\": speed_loss,\n",
    "            \"optimizer_state_dict\":optimizer.state_dict(),\n",
    "            \"epoch\":epoch\n",
    "            }, save_path)\n",
    "        print('saving success!')\n",
    "        if validation:\n",
    "            print('='*10 + 'starting validation' + '='*10)\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (data, target) in enumerate(tqdm_notebook(validation_loader)):\n",
    "                    if torch.cuda.is_available():\n",
    "                        for w in ['canSteering', 'canSpeed']:\n",
    "                            target[w].cuda()\n",
    "                    prediction = model(data)\n",
    "                    mse1 = (np.square(prediction['canSteering'].cpu() - target['canSteering'].cpu())).mean()\n",
    "                    mse2 = (np.square(prediction['canSpeed'].cpu() - target['canSpeed'].cpu())).mean()\n",
    "                    if normalize_targets:\n",
    "                        mse1 = mse1 * target_std['canSteering'] ** 2\n",
    "                        mse2 = mse2 * target_std['canSpeed'] ** 2\n",
    "                    validation_metrics['angle_loss'].setdefault(str(epoch), []).append(mse1)\n",
    "                    validation_metrics['speed_loss'].setdefault(str(epoch), []).append(mse2)\n",
    "            print('angle_loss: %.2f speed_loss: %.2f' % (np.mean(validation_metrics['angle_loss'][str(epoch)]), \n",
    "                  np.mean(validation_metrics['speed_loss'][str(epoch)])))\n",
    "            print('='*10 + 'validation finished' + '='*10)\n",
    "    return train_metrics, validation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_path does not exist!\n",
      "==========start 1 epoch==========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f669c8c3eb4a869a6ceafcbd5f3a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4894), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1, batch:   200] time: 256.68 angle_loss: 1634.36 speed_loss: 24.05\n",
      "[epoch: 1, batch:   400] time: 255.99 angle_loss: 1804.75 speed_loss: 12.98\n",
      "[epoch: 1, batch:   600] time: 256.53 angle_loss: 1666.50 speed_loss: 10.96\n",
      "[epoch: 1, batch:   800] time: 256.15 angle_loss: 1603.54 speed_loss: 9.59\n",
      "[epoch: 1, batch:  1000] time: 256.70 angle_loss: 1580.01 speed_loss: 9.06\n",
      "[epoch: 1, batch:  1200] time: 256.13 angle_loss: 1280.89 speed_loss: 7.53\n",
      "[epoch: 1, batch:  1400] time: 255.73 angle_loss: 1767.60 speed_loss: 7.43\n",
      "[epoch: 1, batch:  1600] time: 255.96 angle_loss: 1581.20 speed_loss: 6.87\n",
      "[epoch: 1, batch:  1800] time: 256.01 angle_loss: 1427.19 speed_loss: 6.61\n",
      "[epoch: 1, batch:  2000] time: 256.37 angle_loss: 1230.28 speed_loss: 6.02\n",
      "[epoch: 1, batch:  2200] time: 256.57 angle_loss: 1270.19 speed_loss: 5.98\n",
      "[epoch: 1, batch:  2400] time: 257.07 angle_loss: 1497.00 speed_loss: 5.64\n",
      "[epoch: 1, batch:  2600] time: 257.02 angle_loss: 1157.96 speed_loss: 5.26\n",
      "[epoch: 1, batch:  2800] time: 256.40 angle_loss: 1467.52 speed_loss: 5.93\n",
      "[epoch: 1, batch:  3000] time: 256.80 angle_loss: 1324.44 speed_loss: 5.02\n",
      "[epoch: 1, batch:  3200] time: 256.75 angle_loss: 1112.63 speed_loss: 4.72\n",
      "[epoch: 1, batch:  3400] time: 256.25 angle_loss: 1259.33 speed_loss: 4.89\n",
      "[epoch: 1, batch:  3600] time: 256.57 angle_loss: 1447.77 speed_loss: 4.76\n",
      "[epoch: 1, batch:  3800] time: 256.62 angle_loss: 1338.79 speed_loss: 4.55\n",
      "[epoch: 1, batch:  4000] time: 256.80 angle_loss: 1514.28 speed_loss: 4.68\n",
      "[epoch: 1, batch:  4200] time: 257.26 angle_loss: 1255.90 speed_loss: 4.79\n",
      "[epoch: 1, batch:  4400] time: 256.32 angle_loss: 1106.65 speed_loss: 4.54\n",
      "[epoch: 1, batch:  4600] time: 255.93 angle_loss: 1145.62 speed_loss: 4.28\n",
      "[epoch: 1, batch:  4800] time: 255.91 angle_loss: 782.51 speed_loss: 4.44\n",
      "\n",
      "==========saving the model to../output/non_local/10-08-01:01_non_local.pth==========\n",
      "saving success!\n",
      "==========starting validation==========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882b56a43e224b03bec0be1e8e60ae60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=322), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "angle_loss: 781.46 speed_loss: 6.59\n",
      "==========validation finished==========\n",
      "==========start 2 epoch==========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906db28fc0434ca2ba3ab08c6e130039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4894), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 2, batch:   200] time: 257.11 angle_loss: 958.30 speed_loss: 3.97\n",
      "[epoch: 2, batch:   400] time: 256.37 angle_loss: 1064.66 speed_loss: 4.34\n",
      "[epoch: 2, batch:   600] time: 255.95 angle_loss: 1049.41 speed_loss: 3.82\n",
      "[epoch: 2, batch:   800] time: 255.76 angle_loss: 843.15 speed_loss: 3.64\n",
      "[epoch: 2, batch:  1000] time: 256.02 angle_loss: 1181.11 speed_loss: 4.11\n",
      "[epoch: 2, batch:  1200] time: 256.83 angle_loss: 657.23 speed_loss: 3.33\n",
      "[epoch: 2, batch:  1400] time: 256.72 angle_loss: 1004.09 speed_loss: 3.77\n",
      "[epoch: 2, batch:  1600] time: 256.82 angle_loss: 939.48 speed_loss: 3.65\n",
      "[epoch: 2, batch:  1800] time: 256.79 angle_loss: 718.26 speed_loss: 3.40\n",
      "[epoch: 2, batch:  2000] time: 256.81 angle_loss: 757.59 speed_loss: 3.43\n",
      "[epoch: 2, batch:  2200] time: 256.86 angle_loss: 646.92 speed_loss: 3.49\n",
      "[epoch: 2, batch:  2400] time: 256.45 angle_loss: 886.93 speed_loss: 3.44\n",
      "[epoch: 2, batch:  2600] time: 256.46 angle_loss: 640.44 speed_loss: 3.13\n",
      "[epoch: 2, batch:  2800] time: 255.51 angle_loss: 900.35 speed_loss: 3.69\n",
      "[epoch: 2, batch:  3000] time: 256.10 angle_loss: 763.45 speed_loss: 3.25\n",
      "[epoch: 2, batch:  3200] time: 255.90 angle_loss: 741.87 speed_loss: 3.04\n",
      "[epoch: 2, batch:  3400] time: 256.13 angle_loss: 644.76 speed_loss: 3.29\n",
      "[epoch: 2, batch:  3600] time: 256.20 angle_loss: 748.99 speed_loss: 3.04\n",
      "[epoch: 2, batch:  3800] time: 256.17 angle_loss: 664.47 speed_loss: 3.05\n",
      "[epoch: 2, batch:  4000] time: 256.28 angle_loss: 958.53 speed_loss: 3.15\n",
      "[epoch: 2, batch:  4200] time: 256.34 angle_loss: 749.65 speed_loss: 3.36\n",
      "[epoch: 2, batch:  4400] time: 256.94 angle_loss: 557.86 speed_loss: 3.06\n",
      "[epoch: 2, batch:  4600] time: 256.75 angle_loss: 761.90 speed_loss: 3.03\n",
      "[epoch: 2, batch:  4800] time: 256.91 angle_loss: 442.86 speed_loss: 3.13\n",
      "\n",
      "==========saving the model to../output/non_local/10-08-01:01_non_local.pth==========\n",
      "saving success!\n",
      "==========starting validation==========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533be2e7722445f6b0a19329bd53e874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=322), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "angle_loss: 689.30 speed_loss: 6.56\n",
      "==========validation finished==========\n",
      "==========start 3 epoch==========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7fee21343443cd940b2f25f80857e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4894), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 3, batch:   200] time: 257.07 angle_loss: 605.73 speed_loss: 2.84\n",
      "[epoch: 3, batch:   400] time: 256.82 angle_loss: 700.73 speed_loss: 2.95\n",
      "[epoch: 3, batch:   600] time: 256.81 angle_loss: 679.68 speed_loss: 2.59\n",
      "[epoch: 3, batch:   800] time: 256.79 angle_loss: 518.96 speed_loss: 2.55\n",
      "[epoch: 3, batch:  1000] time: 256.80 angle_loss: 817.13 speed_loss: 2.98\n",
      "[epoch: 3, batch:  1200] time: 256.79 angle_loss: 375.93 speed_loss: 2.28\n",
      "[epoch: 3, batch:  1400] time: 256.81 angle_loss: 505.35 speed_loss: 2.53\n",
      "[epoch: 3, batch:  1600] time: 256.80 angle_loss: 525.98 speed_loss: 2.54\n",
      "[epoch: 3, batch:  1800] time: 256.73 angle_loss: 434.58 speed_loss: 2.64\n",
      "[epoch: 3, batch:  2000] time: 256.74 angle_loss: 511.87 speed_loss: 2.40\n",
      "[epoch: 3, batch:  2200] time: 256.68 angle_loss: 386.25 speed_loss: 2.48\n",
      "[epoch: 3, batch:  2400] time: 256.76 angle_loss: 564.87 speed_loss: 2.42\n",
      "[epoch: 3, batch:  2600] time: 256.72 angle_loss: 344.99 speed_loss: 2.28\n",
      "[epoch: 3, batch:  2800] time: 256.48 angle_loss: 463.11 speed_loss: 2.53\n",
      "[epoch: 3, batch:  3000] time: 256.64 angle_loss: 380.66 speed_loss: 2.27\n",
      "[epoch: 3, batch:  3200] time: 256.59 angle_loss: 387.78 speed_loss: 2.11\n",
      "[epoch: 3, batch:  3400] time: 255.56 angle_loss: 422.59 speed_loss: 2.34\n",
      "[epoch: 3, batch:  3600] time: 255.25 angle_loss: 465.52 speed_loss: 2.30\n",
      "[epoch: 3, batch:  3800] time: 254.97 angle_loss: 395.99 speed_loss: 2.36\n",
      "[epoch: 3, batch:  4000] time: 254.86 angle_loss: 672.26 speed_loss: 2.40\n",
      "[epoch: 3, batch:  4200] time: 254.86 angle_loss: 369.28 speed_loss: 2.29\n",
      "[epoch: 3, batch:  4400] time: 254.94 angle_loss: 491.93 speed_loss: 2.27\n",
      "[epoch: 3, batch:  4600] time: 255.29 angle_loss: 484.59 speed_loss: 2.34\n",
      "[epoch: 3, batch:  4800] time: 255.03 angle_loss: 331.25 speed_loss: 2.37\n",
      "\n",
      "==========saving the model to../output/non_local/10-08-01:01_non_local.pth==========\n",
      "saving success!\n",
      "==========starting validation==========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54046d7f037f4b6a9da1f1424634caff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=322), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "angle_loss: 739.99 speed_loss: 7.51\n",
      "==========validation finished==========\n",
      "==========start 4 epoch==========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "760005d174db4dc4ace59284da7f70f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4894), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 4, batch:   200] time: 256.02 angle_loss: 353.85 speed_loss: 2.09\n",
      "[epoch: 4, batch:   400] time: 255.45 angle_loss: 487.88 speed_loss: 2.34\n",
      "[epoch: 4, batch:   600] time: 255.66 angle_loss: 452.23 speed_loss: 1.95\n",
      "[epoch: 4, batch:   800] time: 255.58 angle_loss: 289.39 speed_loss: 1.81\n",
      "[epoch: 4, batch:  1000] time: 255.52 angle_loss: 470.18 speed_loss: 2.13\n",
      "[epoch: 4, batch:  1200] time: 255.57 angle_loss: 289.09 speed_loss: 1.72\n",
      "[epoch: 4, batch:  1400] time: 255.65 angle_loss: 431.31 speed_loss: 1.94\n",
      "[epoch: 4, batch:  1600] time: 255.06 angle_loss: 408.26 speed_loss: 2.00\n",
      "[epoch: 4, batch:  1800] time: 254.99 angle_loss: 352.53 speed_loss: 2.04\n",
      "[epoch: 4, batch:  2000] time: 255.29 angle_loss: 336.35 speed_loss: 1.79\n",
      "[epoch: 4, batch:  2200] time: 255.17 angle_loss: 301.92 speed_loss: 1.84\n",
      "[epoch: 4, batch:  2400] time: 255.48 angle_loss: 370.22 speed_loss: 1.85\n",
      "[epoch: 4, batch:  2600] time: 254.95 angle_loss: 249.79 speed_loss: 1.73\n",
      "[epoch: 4, batch:  2800] time: 255.05 angle_loss: 301.93 speed_loss: 1.85\n",
      "[epoch: 4, batch:  3000] time: 255.51 angle_loss: 275.52 speed_loss: 1.62\n",
      "[epoch: 4, batch:  3200] time: 255.25 angle_loss: 223.67 speed_loss: 1.55\n",
      "[epoch: 4, batch:  3400] time: 255.79 angle_loss: 266.25 speed_loss: 1.71\n",
      "[epoch: 4, batch:  3600] time: 256.01 angle_loss: 259.40 speed_loss: 1.76\n",
      "[epoch: 4, batch:  3800] time: 255.74 angle_loss: 270.22 speed_loss: 1.71\n",
      "[epoch: 4, batch:  4000] time: 255.60 angle_loss: 488.76 speed_loss: 1.97\n",
      "[epoch: 4, batch:  4200] time: 255.66 angle_loss: 302.54 speed_loss: 1.85\n",
      "[epoch: 4, batch:  4400] time: 255.50 angle_loss: 318.80 speed_loss: 1.70\n",
      "[epoch: 4, batch:  4600] time: 256.83 angle_loss: 346.23 speed_loss: 1.76\n",
      "[epoch: 4, batch:  4800] time: 256.70 angle_loss: 217.20 speed_loss: 1.88\n",
      "\n",
      "==========saving the model to../output/non_local/10-08-01:01_non_local.pth==========\n",
      "saving success!\n",
      "==========starting validation==========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85750ebe03934e14969870c4244e2ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=322), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "angle_loss: 707.92 speed_loss: 6.75\n",
      "==========validation finished==========\n",
      "==========start 5 epoch==========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71aa20338e514b99a843955804390b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4894), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 5, batch:   200] time: 255.79 angle_loss: 232.50 speed_loss: 1.59\n",
      "[epoch: 5, batch:   400] time: 254.54 angle_loss: 380.46 speed_loss: 1.84\n",
      "[epoch: 5, batch:   600] time: 254.78 angle_loss: 323.23 speed_loss: 1.57\n",
      "[epoch: 5, batch:   800] time: 255.31 angle_loss: 272.57 speed_loss: 1.52\n",
      "[epoch: 5, batch:  1000] time: 255.27 angle_loss: 350.67 speed_loss: 1.72\n",
      "[epoch: 5, batch:  1200] time: 255.35 angle_loss: 209.07 speed_loss: 1.45\n",
      "[epoch: 5, batch:  1400] time: 255.36 angle_loss: 335.59 speed_loss: 1.52\n",
      "[epoch: 5, batch:  1600] time: 255.48 angle_loss: 282.92 speed_loss: 1.64\n",
      "[epoch: 5, batch:  1800] time: 255.45 angle_loss: 289.57 speed_loss: 1.69\n",
      "[epoch: 5, batch:  2000] time: 255.12 angle_loss: 272.27 speed_loss: 1.46\n",
      "[epoch: 5, batch:  2200] time: 255.40 angle_loss: 189.89 speed_loss: 1.48\n",
      "[epoch: 5, batch:  2400] time: 255.06 angle_loss: 179.62 speed_loss: 1.48\n",
      "[epoch: 5, batch:  2600] time: 255.40 angle_loss: 202.75 speed_loss: 1.44\n",
      "[epoch: 5, batch:  2800] time: 255.33 angle_loss: 268.45 speed_loss: 1.55\n",
      "[epoch: 5, batch:  3000] time: 255.27 angle_loss: 262.82 speed_loss: 1.39\n",
      "[epoch: 5, batch:  3200] time: 255.11 angle_loss: 219.95 speed_loss: 1.27\n",
      "[epoch: 5, batch:  3400] time: 255.27 angle_loss: 200.31 speed_loss: 1.40\n",
      "[epoch: 5, batch:  3600] time: 254.65 angle_loss: 192.92 speed_loss: 1.32\n",
      "[epoch: 5, batch:  3800] time: 255.03 angle_loss: 179.56 speed_loss: 1.28\n",
      "[epoch: 5, batch:  4000] time: 254.95 angle_loss: 352.44 speed_loss: 1.44\n",
      "[epoch: 5, batch:  4200] time: 255.23 angle_loss: 216.19 speed_loss: 1.42\n",
      "[epoch: 5, batch:  4400] time: 255.33 angle_loss: 320.25 speed_loss: 1.38\n",
      "[epoch: 5, batch:  4600] time: 255.43 angle_loss: 238.82 speed_loss: 1.32\n",
      "[epoch: 5, batch:  4800] time: 255.39 angle_loss: 203.69 speed_loss: 1.47\n",
      "\n",
      "==========saving the model to../output/non_local/10-08-01:01_non_local.pth==========\n",
      "saving success!\n",
      "==========starting validation==========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f17dfbe862849ca84ef210d2cbe6fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=322), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "angle_loss: 738.12 speed_loss: 6.67\n",
      "==========validation finished==========\n"
     ]
    }
   ],
   "source": [
    "NOW = datetime.now().strftime(\"%m-%d-%H:%M\")\n",
    "MODEL_NAME = 'non_local'\n",
    "\n",
    "if not os.path.isdir(os.path.join('../output', MODEL_NAME)):\n",
    "    os.mkdir(os.path.join('../output', MODEL_NAME))\n",
    "\n",
    "LOAD_PATH = os.path.join('../output', MODEL_NAME, '.pth')\n",
    "SAVE_PATH = os.path.join('../output', MODEL_NAME, NOW + '_' + MODEL_NAME + '.pth')\n",
    "\n",
    "model = NonLocalModel()\n",
    "criterion =nn.MSELoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001)\n",
    "\n",
    "result = train_nn(train_loader, validation_loader, model, optimizer, criterion, epochs=5, \n",
    "                  validation=True, load_path=LOAD_PATH, save_path=SAVE_PATH, print_freq=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wmytfALkchq6"
   },
   "source": [
    "## Creating a submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uL0kP0lYchq7"
   },
   "outputs": [],
   "source": [
    "def add_results(results, output):\n",
    "    steering = np.squeeze(output['canSteering'].cpu().data.numpy())\n",
    "    speed = np.squeeze(output['canSpeed'].cpu().data.numpy())\n",
    "    if normalize_targets:\n",
    "        steering = (steering*target_std['canSteering'])+target_mean['canSteering']\n",
    "        speed = (speed*target_std['canSpeed'])+target_mean['canSpeed']\n",
    "    if np.isscalar(steering):\n",
    "        steering = [steering]\n",
    "    if np.isscalar(speed):\n",
    "        speed = [speed]\n",
    "    results['canSteering'].extend(steering)\n",
    "    results['canSpeed'].extend(speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sf28f1B6chq-"
   },
   "source": [
    "We use pandas to create a submission file which is simply a 2-column csv with a canSteering and canSpeed prediction for each row in the **drive360_test.csv** a total of 305437 rows/predictions not including the header. See the **sample_submission.csv** file as an example.\n",
    "\n",
    "IMPORTANT: for the test phase indices will start 10s (100 samples) into each chapter this is to allow challenge participants to experiment with different temporal settings of data input. If challenge participants have a greater temporal length than 10s for each training sample, then they must write a custom function here. Please check out the **dataset.py** file for additional explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ogBR8mhFchq_"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f768323e71048b09abeb4c16dd68288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=876), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = {'canSteering': [],\n",
    "           'canSpeed': []}\n",
    "\n",
    "model = NonLocalModel()\n",
    "model.cuda()\n",
    "MODEL_NAME = 'non_local'\n",
    "LOAD_PATH = os.path.join('../output', MODEL_NAME, '10-08-01:01_non_local.pth')\n",
    "checkpoint = torch.load(LOAD_PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tqdm_notebook(test_loader)):\n",
    "        prediction = model(data)\n",
    "        add_results(results, prediction)\n",
    "\n",
    "df = pd.DataFrame.from_dict(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>canSteering</th>\n",
       "      <th>canSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-8.673856</td>\n",
       "      <td>13.076159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-5.281831</td>\n",
       "      <td>13.105808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-8.963642</td>\n",
       "      <td>12.793524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-23.991327</td>\n",
       "      <td>12.559094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-9.170262</td>\n",
       "      <td>12.694208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   canSteering   canSpeed\n",
       "0    -8.673856  13.076159\n",
       "1    -5.281831  13.105808\n",
       "2    -8.963642  12.793524\n",
       "3   -23.991327  12.559094\n",
       "4    -9.170262  12.694208"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279863\n"
     ]
    }
   ],
   "source": [
    "## linear interpolation\n",
    "from scipy.interpolate import interp1d\n",
    "file = os.path.join('../output', MODEL_NAME, 'submission.csv')\n",
    "output = {\n",
    "    'canSteering': [],\n",
    "    'canSpeed': []\n",
    "}\n",
    "test_sample = pd.read_csv('/home/jupyter/competition/Sample2/test_sample2.csv')\n",
    "curr_list = test_sample['chapter'].value_counts()-4\n",
    "test_full = pd.read_csv('/home/jupyter/competition/Sample2/test_full.csv')\n",
    "target_list = test_full['chapter'].value_counts()-100\n",
    "k = 0\n",
    "for ch in test_sample['chapter'].unique():\n",
    "    curr_num = curr_list[ch]\n",
    "    target_num = target_list[ch]\n",
    "    x = list(range(100, 100+20*curr_num, 20))\n",
    "    x.insert(0, 0)\n",
    "    x.append(target_num+100)\n",
    "\n",
    "    newx = list(range(101, target_num+101))\n",
    "    y1, y2 = list(df.iloc[k:(k+curr_num),0]), list(df.iloc[k:(k+curr_num),1])\n",
    "    y1.insert(0, y1[0])\n",
    "    y1.append(y1[-1])\n",
    "\n",
    "    f1 = interp1d(x, y1, kind='linear')\n",
    "    output['canSteering'].extend(f1(newx))\n",
    "    y2.insert(0, y2[0])\n",
    "    y2.append(y2[-1])\n",
    "    f2 = interp1d(x, y2, kind='linear')\n",
    "    output['canSpeed'].extend(f2(newx))\n",
    "    k += curr_num\n",
    "    \n",
    "output_df = pd.DataFrame(output)\n",
    "print(len(output_df))\n",
    "output_df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13422, 2)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "zxx_trybaseline.ipynb",
   "provenance": [
    {
     "file_id": "1QKQXTMXpTsQc4Pb4xCgBCzd_Kxa-5Q5g",
     "timestamp": 1569968743899
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
